{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33681dd1",
   "metadata": {},
   "source": [
    "Necessary imports and helper functions for displaying points, boxes, and masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b28288",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bc90d5",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-18T12:43:03.911367474Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_mask(mask, ax, random_color=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "    \n",
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)   \n",
    "    \n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23842fb2",
   "metadata": {},
   "source": [
    "## Example image"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ds_img_embedding = h5py.File('/home/ron/Documents/SemiSAM/data/Graz_img_embedding.h5', 'r')['img_embedding']\n",
    "ds_img_embedding.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-18T12:43:03.911514120Z"
    }
   },
   "id": "5becebe8054bb2fa",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2e4f6b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-18T12:43:03.911597427Z"
    }
   },
   "outputs": [],
   "source": [
    "from os import getcwd\n",
    "print(getcwd())\n",
    "\n",
    "img_name = '2639_0713211442_01_WRI-R1_M005'\n",
    "image = cv2.imread(f'../data/img_only_front_all_left/{img_name}.png', cv2.IMREAD_GRAYSCALE)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "image = cv2.resize(image, (224, 384), interpolation=cv2.INTER_LINEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30125fd",
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "start_time": "2024-01-18T12:43:03.911671980Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(image)\n",
    "plt.axis('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b228b8",
   "metadata": {},
   "source": [
    "## Selecting objects with SAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb1927b",
   "metadata": {},
   "source": [
    "First, load the SAM model and predictor. Change the path below to point to the SAM checkpoint. Running on CUDA and using the default model are recommended for best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e28150b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-18T12:43:03.915468404Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "\n",
    "sam_checkpoint = \"/home/ron/Documents/SemiSAM/data/sam_vit_h_4b8939.pth\"\n",
    "model_type = \"vit_h\"\n",
    "\n",
    "device = \"cpu\"#\"cuda\"\n",
    "\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=device)\n",
    "\n",
    "predictor = SamPredictor(sam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c925e829",
   "metadata": {},
   "source": [
    "Process the image to produce an image embedding by calling `SamPredictor.set_image`. `SamPredictor` remembers this embedding and will use it for subsequent mask prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95d48dd",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-18T12:43:03.915586189Z"
    }
   },
   "outputs": [],
   "source": [
    "predictor.set_image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fc7a46",
   "metadata": {},
   "source": [
    "To select the truck, choose a point on it. Points are input to the model in (x,y) format and come with labels 1 (foreground point) or 0 (background point). Multiple points can be input; here we use only one. The chosen point will be shown as a star on the image."
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "f = h5py.File('/home/ron/Documents/KidsBoneChecker/datasets/data/GRAZPEDWRI-DX/SegGraz_nnunet_predictions.h5', 'r')\n",
    "lbl_idx_mapping = json.loads(f.attrs['labels'])\n",
    "ds_seg_masks = f['nnUNet_prediction']\n",
    "seg_masks = torch.from_numpy(ds_seg_masks[img_name][:])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-18T12:43:03.915650138Z"
    }
   },
   "id": "aa65546f5abf4595",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.imshow(seg_masks.float().argmax(0))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-18T12:43:03.915702489Z"
    }
   },
   "id": "4f79322a735ba503",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from segment_anything.utils.prompt_utils import PromptExtractor\n",
    "\n",
    "prompt_extractor = PromptExtractor(seg_masks)\n",
    "prompts= prompt_extractor.extract()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-18T12:43:03.915753899Z"
    }
   },
   "id": "c39b995e2163a3c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "prompt = prompts[-2]\n",
    "input_point = torch.cat([prompt.pos_seeds, prompt.neg_seeds]).numpy()\n",
    "input_label = np.array([1] * prompt.pos_seeds.shape[0] + [0] * prompt.neg_seeds.shape[0])\n",
    "input_box = prompt.box.numpy()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(image)\n",
    "show_points(input_point, input_label, plt.gca())\n",
    "plt.axis('on')\n",
    "plt.show()  "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-18T12:43:03.915810720Z"
    }
   },
   "id": "a91ba973",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SAM predictor"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52e21408b6627c61"
  },
  {
   "cell_type": "markdown",
   "id": "c765e952",
   "metadata": {},
   "source": [
    "Predict with `SamPredictor.predict`. The model returns masks, quality predictions for those masks, and low resolution mask logits that can be passed to the next iteration of prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5373fd68",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-18T12:43:03.916923173Z"
    }
   },
   "outputs": [],
   "source": [
    "masks, scores, logits = predictor.predict(\n",
    "    point_coords=input_point,\n",
    "    point_labels=input_label,\n",
    "    multimask_output=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f0e938",
   "metadata": {},
   "source": [
    "With `multimask_output=True` (the default setting), SAM outputs 3 masks, where `scores` gives the model's own estimation of the quality of these masks. This setting is intended for ambiguous input prompts, and helps the model disambiguate different objects consistent with the prompt. When `False`, it will return a single mask. For ambiguous prompts such as a single point, it is recommended to use `multimask_output=True` even if only a single mask is desired; the best single mask can be chosen by picking the one with the highest score returned in `scores`. This will often result in a better mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47821187",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-18T12:43:03.916994674Z"
    }
   },
   "outputs": [],
   "source": [
    "masks.shape  # (number_of_masks) x H x W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c227a6",
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "start_time": "2024-01-18T12:43:03.917050760Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, (mask, score) in enumerate(zip(masks, scores)):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(image)\n",
    "    show_mask(mask, plt.gca())\n",
    "    show_points(input_point, input_label, plt.gca())\n",
    "    plt.title(f\"Mask {i+1}, Score: {score:.3f}\", fontsize=18)\n",
    "    plt.axis('off')\n",
    "    plt.show()  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d6d29a",
   "metadata": {},
   "source": [
    "The single input point is ambiguous, and the model has returned multiple objects consistent with it. To obtain a single object, multiple points can be provided. If available, a mask from a previous iteration can also be supplied to the model to aid in prediction. When specifying a single object with multiple prompts, a single mask can be requested by setting `multimask_output=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6923b94",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-18T12:43:03.917086330Z"
    }
   },
   "outputs": [],
   "source": [
    "mask_input = logits[np.argmax(scores), :, :]  # Choose the model's best mask"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Try mask refinement with additional point prompts"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cfafe69488b29ebe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98f96a1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-18T12:43:03.917122604Z"
    }
   },
   "outputs": [],
   "source": [
    "masks, _, _ = predictor.predict(\n",
    "    point_coords=input_point,\n",
    "    point_labels=input_label,\n",
    "    mask_input=mask_input[None, :, :],\n",
    "    multimask_output=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06d5c8d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-18T12:43:03.917158506Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(image)\n",
    "show_mask(masks, plt.gca())\n",
    "show_points(input_point, input_label, plt.gca())\n",
    "plt.axis('off')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35a8814",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-18T12:43:03.917194051Z"
    }
   },
   "outputs": [],
   "source": [
    "masks, scores, _ = predictor.predict(\n",
    "    point_coords=None,\n",
    "    point_labels=None,\n",
    "    box=input_box[None, :],\n",
    "    multimask_output=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984b79c1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-18T12:43:03.917227319Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, (mask, score) in enumerate(zip(masks, scores)):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(image)\n",
    "    show_mask(mask, plt.gca())\n",
    "    show_box(input_box, plt.gca())\n",
    "    plt.title(f\"Mask {i+1}, Score: {score:.3f}\", fontsize=18)\n",
    "    plt.axis('off')\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SAM with loaded image embedding"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c5d47c55f8e2d336"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "predictor.reset_image()\n",
    "\n",
    "predictor.features = torch.from_numpy(ds_img_embedding[img_name]['features'][:])\n",
    "predictor.original_size = ds_img_embedding[img_name].attrs['original_size'].tolist()\n",
    "predictor.input_size = ds_img_embedding[img_name].attrs['input_size'].tolist()\n",
    "predictor.is_image_set = True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-18T12:43:03.917260295Z"
    }
   },
   "id": "6e5b38cc323e7d2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from segment_anything.utils.prompt_utils import scale_box\n",
    "\n",
    "transformed_box = scale_box(torch.from_numpy(input_box).unsqueeze(0), image.shape[:2], predictor.original_size).numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-18T12:43:03.917293501Z"
    }
   },
   "id": "d80fec59f70706bd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "masks, _, _ = predictor.predict(\n",
    "    point_coords=None,\n",
    "    point_labels=None,\n",
    "    box=transformed_box,\n",
    "    multimask_output=False,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-18T12:43:03.917342032Z"
    }
   },
   "id": "d7d542f3233a1079",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cv2.imread(f'../data/img_only_front_all_left/{img_name}.png', cv2.IMREAD_GRAYSCALE), 'gray')\n",
    "show_mask(masks[0], plt.gca())\n",
    "show_box(transformed_box[0], plt.gca())\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-18T12:43:03.917376839Z"
    }
   },
   "id": "af8fc3fe0da56686",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Only prompt embedding and mask decoding"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c112acc492ed6a8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from segment_anything.utils.prompt_utils import scale_box, scale_coords\n",
    "\n",
    "transformed_points = scale_coords(torch.from_numpy(input_point), image.shape[:2], predictor.input_size)\n",
    "\n",
    "with torch.inference_mode():\n",
    "    sparse_embeddings, dense_embeddings = sam.prompt_encoder(\n",
    "        points=(transformed_points.unsqueeze(0), torch.from_numpy(input_label).unsqueeze(0)),\n",
    "        boxes = None,\n",
    "        masks = None\n",
    "    )\n",
    "    \n",
    "    # Predict masks\n",
    "    low_res_masks, iou_predictions = sam.mask_decoder(\n",
    "        image_embeddings=predictor.features,\n",
    "        image_pe=sam.prompt_encoder.get_dense_pe(),\n",
    "        sparse_prompt_embeddings=sparse_embeddings,\n",
    "        dense_prompt_embeddings=dense_embeddings,\n",
    "        multimask_output=False,\n",
    "    )\n",
    "    \n",
    "    # Upscale the masks to the original image resolution\n",
    "    masks = sam.postprocess_masks(low_res_masks, predictor.input_size, predictor.original_size)\n",
    "    masks = masks > sam.mask_threshold"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-18T12:43:03.958160160Z"
    }
   },
   "id": "92d91ec6a2413c49",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cv2.imread(f'../data/img_only_front_all_left/{img_name}.png', cv2.IMREAD_GRAYSCALE), 'gray')\n",
    "show_mask(masks[0], plt.gca())\n",
    "show_points(scale_coords(torch.from_numpy(input_point), image.shape[:2], predictor.original_size), input_label, plt.gca())\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-18T12:43:03.958325023Z"
    }
   },
   "id": "9a29c6290a3038a0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "transformed_box = scale_box(torch.from_numpy(input_box).unsqueeze(0), image.shape[:2], predictor.input_size)\n",
    "\n",
    "with torch.inference_mode():\n",
    "    sparse_embeddings, dense_embeddings = sam.prompt_encoder(\n",
    "        points=None,\n",
    "        boxes=transformed_box,\n",
    "        masks=None\n",
    "    )\n",
    "\n",
    "    # Predict masks\n",
    "    low_res_masks, iou_predictions = sam.mask_decoder(\n",
    "        image_embeddings=predictor.features,\n",
    "        image_pe=sam.prompt_encoder.get_dense_pe(),\n",
    "        sparse_prompt_embeddings=sparse_embeddings,\n",
    "        dense_prompt_embeddings=dense_embeddings,\n",
    "        multimask_output=False,\n",
    "    )\n",
    "\n",
    "    # Upscale the masks to the original image resolution\n",
    "    masks = sam.postprocess_masks(low_res_masks, predictor.input_size, predictor.original_size)\n",
    "    masks = masks > sam.mask_threshold\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cv2.imread(f'../data/img_only_front_all_left/{img_name}.png', cv2.IMREAD_GRAYSCALE), 'gray')\n",
    "show_mask(masks[0], plt.gca())\n",
    "show_box(scale_box(torch.from_numpy(input_box).unsqueeze(0), image.shape[:2], predictor.original_size)[0], plt.gca())\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-18T12:43:03.958371363Z"
    }
   },
   "id": "6c2c0e1e3bec921b",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
